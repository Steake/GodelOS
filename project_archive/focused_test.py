#!/usr/bin/env python3
"""
Focused test for core enhanced metacognition functionality.

This test verifies the essential components work without any
complex imports or circular dependencies.
"""

import os
import sys
import json
import tempfile
from pathlib import Path

print("üß™ ENHANCED METACOGNITION FOCUSED TESTS")
print("=" * 45)

def test_1_configuration():
    """Test 1: Configuration management"""
    print("\n1Ô∏è‚É£ Testing Configuration Management...")
    
    try:
        # Add backend to path
        sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'backend'))
        
        from config_manager import ConfigurationManager, get_config
        
        # Test default config
        config = get_config()
        print(f"  ‚úÖ Default configuration loaded")
        print(f"  ‚úÖ Cognitive streaming enabled: {config.cognitive_streaming.enabled}")
        print(f"  ‚úÖ Autonomous learning enabled: {config.autonomous_learning.enabled}")
        
        # Test feature flags
        from config_manager import is_feature_enabled
        result = is_feature_enabled('enhanced_metacognition')
        print(f"  ‚úÖ Feature flag check works: {result}")
        
        return True
    except Exception as e:
        print(f"  ‚ùå Configuration test failed: {e}")
        return False

def test_2_cognitive_models():
    """Test 2: Cognitive models direct import"""
    print("\n2Ô∏è‚É£ Testing Cognitive Models...")
    
    try:
        # Import models directly
        models_path = os.path.join(os.path.dirname(__file__), 'backend', 'metacognition_modules')
        sys.path.insert(0, models_path)
        
        import cognitive_models as cm
        
        # Test model creation
        gap = cm.KnowledgeGap(
            type=cm.KnowledgeGapType.CONCEPT_MISSING,
            query="Test query",
            confidence=0.5
        )
        print(f"  ‚úÖ KnowledgeGap created: {gap.id[:8]}...")
        
        event = cm.CognitiveEvent(type=cm.CognitiveEventType.QUERY_STARTED)
        print(f"  ‚úÖ CognitiveEvent created: {event.event_id[:8]}...")
        
        plan = cm.AcquisitionPlan(strategy=cm.AcquisitionStrategy.CONCEPT_EXPANSION)
        print(f"  ‚úÖ AcquisitionPlan created: {plan.plan_id[:8]}...")
        
        # Test serialization
        event_json = cm.serialize_cognitive_event(event)
        event_data = json.loads(event_json)
        print(f"  ‚úÖ Serialization works: {event_data['type']}")
        
        return True
    except Exception as e:
        print(f"  ‚ùå Cognitive models test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_3_file_structure():
    """Test 3: File structure verification"""
    print("\n3Ô∏è‚É£ Testing File Structure...")
    
    critical_files = [
        "backend/config_manager.py",
        "backend/enhanced_cognitive_api.py", 
        "backend/config/enhanced_metacognition_config.yaml",
        "backend/metacognition_modules/cognitive_models.py",
        "svelte-frontend/src/stores/enhanced-cognitive.js",
    ]
    
    present = 0
    for file_path in critical_files:
        if Path(file_path).exists():
            print(f"  ‚úÖ {file_path}")
            present += 1
        else:
            print(f"  ‚ùå {file_path}")
    
    success_rate = present / len(critical_files)
    print(f"  üìä Files present: {present}/{len(critical_files)} ({success_rate:.1%})")
    
    return success_rate >= 0.8

def test_4_yaml_config_file():
    """Test 4: YAML configuration file validity"""
    print("\n4Ô∏è‚É£ Testing YAML Configuration...")
    
    try:
        import yaml
        
        config_path = "backend/config/enhanced_metacognition_config.yaml"
        if not Path(config_path).exists():
            print(f"  ‚ùå Config file not found: {config_path}")
            return False
        
        with open(config_path, 'r') as f:
            config_data = yaml.safe_load(f)
        
        # Verify key sections
        required_sections = [
            'cognitive_streaming', 'autonomous_learning', 
            'knowledge_acquisition', 'health_monitoring'
        ]
        
        for section in required_sections:
            if section in config_data:
                print(f"  ‚úÖ Section '{section}' present")
            else:
                print(f"  ‚ùå Section '{section}' missing")
                return False
        
        return True
    except Exception as e:
        print(f"  ‚ùå YAML config test failed: {e}")
        return False

def test_5_svelte_components():
    """Test 5: Svelte component files"""
    print("\n5Ô∏è‚É£ Testing Svelte Components...")
    
    svelte_files = [
        "svelte-frontend/src/stores/enhanced-cognitive.js",
        "svelte-frontend/src/components/core/StreamOfConsciousnessMonitor.svelte",
        "svelte-frontend/src/components/dashboard/EnhancedCognitiveDashboard.svelte",
    ]
    
    present = 0
    for file_path in svelte_files:
        if Path(file_path).exists():
            # Check if file has content
            size = Path(file_path).stat().st_size
            print(f"  ‚úÖ {Path(file_path).name} ({size} bytes)")
            present += 1
        else:
            print(f"  ‚ùå {Path(file_path).name}")
    
    success_rate = present / len(svelte_files)
    print(f"  üìä Components present: {present}/{len(svelte_files)} ({success_rate:.1%})")
    
    return success_rate >= 0.8

def test_6_api_structure():
    """Test 6: API structure validation"""
    print("\n6Ô∏è‚É£ Testing API Structure...")
    
    try:
        # Test that we can at least read the API file
        api_file = "backend/enhanced_cognitive_api.py"
        if not Path(api_file).exists():
            print(f"  ‚ùå API file not found")
            return False
        
        with open(api_file, 'r') as f:
            content = f.read()
        
        # Check for key components
        checks = [
            ('router = APIRouter', 'FastAPI router'),
            ('CognitiveStreamConfig', 'Configuration models'),
            ('websocket', 'WebSocket support'),
            ('@router.', 'Route definitions'),
        ]
        
        for check, description in checks:
            if check in content:
                print(f"  ‚úÖ {description} found")
            else:
                print(f"  ‚ùå {description} missing")
                return False
        
        return True
    except Exception as e:
        print(f"  ‚ùå API structure test failed: {e}")
        return False

def run_all_tests():
    """Run all focused tests"""
    tests = [
        ("Configuration Management", test_1_configuration),
        ("Cognitive Models", test_2_cognitive_models),
        ("File Structure", test_3_file_structure),
        ("YAML Configuration", test_4_yaml_config_file),
        ("Svelte Components", test_5_svelte_components),
        ("API Structure", test_6_api_structure),
    ]
    
    passed = 0
    total = len(tests)
    
    for name, test_func in tests:
        try:
            if test_func():
                passed += 1
                print(f"‚úÖ {name} PASSED")
            else:
                print(f"‚ùå {name} FAILED")
        except Exception as e:
            print(f"‚ùå {name} FAILED with exception: {e}")
    
    print(f"\n{'='*45}")
    print(f"FOCUSED TEST RESULTS: {passed}/{total} tests passed")
    
    if passed == total:
        print("üéâ ALL FOCUSED TESTS PASSED!")
        print("\n‚ú® Core Enhanced Metacognition Implementation VERIFIED")
        print("üìã Ready for:")
        print("  - Basic configuration management")
        print("  - Cognitive data models")
        print("  - Frontend components")
        print("  - API structure")
        print("\n‚ö†Ô∏è Note: Full system integration may require additional setup")
        print("   to resolve circular import dependencies.")
    else:
        print(f"‚ö†Ô∏è {total - passed} tests failed")
        print("üîß Some components may need additional work")
    
    return passed == total

if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)
